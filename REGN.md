
RIDGE  REGRESSION:
    Ridge regression is also known as Tikhonov Regularization,which is the most commonly used method to approximate  an answer for an equation with no unique solution.This type of problem is very common in machine learning tasks,where the "best" solution must be chosen using limited data.By adding a degree of bias to the regression estimates,ridge regression reduces the standard errors.

LASSO REGRESSION:
    In machine learning,lasso(least absolute shrinkage and selection operator)is a regression method that performs both variable selection and regularization in order to enhance the prediction accuracy and interpretability of the statistical model it produces.

ELASTIC NET REGRESSION:
    In statistics,in the fitting of linear or logistic regression models,the elastic net is a regression method that includes both lasso and ridge regression methods.
    The elastic net method overcomes the limitations and weak variables as with lasso or to reduce them to zero as with ridge.These algorithms are examples of regularized regression. 

 
